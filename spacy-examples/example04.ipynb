{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50bf25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load reference data\n",
    "reference_data = os.path.join(os.getcwd(), \"image_suggestion_system\",\"reference_data.json\")\n",
    "with open(\"reference_data.json\", \"r\") as f:\n",
    "    reference_data = json.load(f)\n",
    "\n",
    "# Load model (downloads automatically first time)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode all reference sentences\n",
    "ref_sentences = [item[\"sentence\"] for item in reference_data]\n",
    "ref_embeddings = model.encode(ref_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a96081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_missing_entities(input_sentence, top_k=2):\n",
    "    # Encode the input sentence\n",
    "    input_embedding = model.encode([input_sentence])\n",
    "    \n",
    "    # Find similarities\n",
    "    similarities = cosine_similarity(input_embedding, ref_embeddings)[0]\n",
    "    \n",
    "    # Get top-K most similar reference sentences\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    # Initialize suggestion sets (to avoid duplicates)\n",
    "    suggestions = {\n",
    "        \"characters\": set(),\n",
    "        \"locations\": set(),\n",
    "        \"actions\": set(),\n",
    "        \"nouns\": set()\n",
    "    }\n",
    "    \n",
    "    # Collect suggestions from top matches\n",
    "    for idx in top_indices:\n",
    "        match = reference_data[idx]\n",
    "        for key in suggestions:\n",
    "            suggestions[key].update(match[key])  # add all items for this key\n",
    "    \n",
    "    # Convert sets back to lists\n",
    "    for key in suggestions:\n",
    "        suggestions[key] = list(suggestions[key])\n",
    "    \n",
    "    return suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efae66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_annotation(annotation):\n",
    "    sentence = annotation[\"sentence\"]\n",
    "    suggestions = suggest_missing_entities(sentence)\n",
    "    \n",
    "    # For each category, add ONLY what‚Äôs missing\n",
    "    for key in [\"characters\", \"locations\", \"actions\", \"nouns\"]:\n",
    "        existing = set(annotation[key])\n",
    "        new_suggestions = [item for item in suggestions[key] if item not in existing]\n",
    "        annotation[key].extend(new_suggestions)  # add new items\n",
    "    \n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8657ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pixabay_query(annotation):\n",
    "    parts = []\n",
    "    \n",
    "    if annotation[\"characters\"]:\n",
    "        parts.append(\" \".join(annotation[\"characters\"]))\n",
    "    if annotation[\"actions\"]:\n",
    "        parts.append(\" \".join(annotation[\"actions\"]))\n",
    "    if annotation[\"locations\"] or annotation[\"nouns\"]:\n",
    "        place_stuff = annotation[\"locations\"] + annotation[\"nouns\"]\n",
    "        parts.append(\"in \" + \" \".join(place_stuff))\n",
    "    \n",
    "    return \" \".join(parts).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daf23224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Enriching annotations and generating Pixabay queries...\n",
      "\n",
      "Sentence: Doubt crept in.\n",
      "‚Üí Characters: []\n",
      "‚Üí Locations: []\n",
      "‚Üí Actions: ['creep']\n",
      "‚Üí Nouns: ['path']\n",
      "‚Üí Pixabay Query: \"creep in path\"\n",
      "------------------------------------------------------------\n",
      "Sentence: Rocks blocked the way.\n",
      "‚Üí Characters: []\n",
      "‚Üí Locations: []\n",
      "‚Üí Actions: ['block']\n",
      "‚Üí Nouns: ['rock', 'way', 'path']\n",
      "‚Üí Pixabay Query: \"block in rock way path\"\n",
      "------------------------------------------------------------\n",
      "Sentence: The wind howled.\n",
      "‚Üí Characters: []\n",
      "‚Üí Locations: []\n",
      "‚Üí Actions: ['howl', 'grow']\n",
      "‚Üí Nouns: ['wind', 'trail']\n",
      "‚Üí Pixabay Query: \"howl grow in wind trail\"\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Your original data (from your example)\n",
    "    test_data = [\n",
    "        {\n",
    "            \"sentence\": \"Doubt crept in.\",\n",
    "            \"characters\": [],\n",
    "            \"locations\": [],\n",
    "            \"actions\": [\"creep\"],\n",
    "            \"nouns\": []\n",
    "        },\n",
    "        {\n",
    "            \"sentence\": \"Rocks blocked the way.\",\n",
    "            \"characters\": [],\n",
    "            \"locations\": [],\n",
    "            \"actions\": [\"block\"],\n",
    "            \"nouns\": [\"rock\", \"way\"]\n",
    "        },\n",
    "        {\n",
    "            \"sentence\": \"The wind howled.\",\n",
    "            \"characters\": [],\n",
    "            \"locations\": [],\n",
    "            \"actions\": [\"howl\"],\n",
    "            \"nouns\": [\"wind\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    print(\"üîç Enriching annotations and generating Pixabay queries...\\n\")\n",
    "\n",
    "    for item in test_data:\n",
    "        enriched = enrich_annotation(item)\n",
    "        query = build_pixabay_query(enriched)\n",
    "        print(f\"Sentence: {item['sentence']}\")\n",
    "        print(f\"‚Üí Characters: {enriched['characters']}\")\n",
    "        print(f\"‚Üí Locations: {enriched['locations']}\")\n",
    "        print(f\"‚Üí Actions: {enriched['actions']}\")\n",
    "        print(f\"‚Üí Nouns: {enriched['nouns']}\")\n",
    "        print(f\"‚Üí Pixabay Query: \\\"{query}\\\"\")\n",
    "        print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9476d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
