{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3c5824",
   "metadata": {},
   "source": [
    "GOAL: Build a Context-Aware Suggestion System\n",
    "Read the whole script/story first.\n",
    "Build a global context (characters, locations, ongoing actions).\n",
    "Use that context + sentence similarity to enrich each sentence.\n",
    "‚úÖ STEP 2: Keep Your reference_data.json (same as before)\n",
    "‚úÖ STEP 3: Load Model & Reference Data (same as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b9f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load reference data\n",
    "with open(\"reference_data.json\", \"r\") as f:\n",
    "    reference_data = json.load(f)\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode reference sentences\n",
    "ref_sentences = [item[\"sentence\"] for item in reference_data]\n",
    "ref_embeddings = model.encode(ref_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e35eb5",
   "metadata": {},
   "source": [
    "‚úÖ STEP 4: Build Global Context While Reading Script\n",
    "We‚Äôll scan the whole script first and collect:\n",
    "All mentioned characters\n",
    "All mentioned locations\n",
    "Common actions and nouns\n",
    "Add this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad18927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_global_context(script_data):\n",
    "    global_chars = set()\n",
    "    global_locs = set()\n",
    "    global_actions = set()\n",
    "    global_nouns = set()\n",
    "\n",
    "    for item in script_data:\n",
    "        global_chars.update(item.get(\"characters\", []))\n",
    "        global_locs.update(item.get(\"locations\", []))\n",
    "        global_actions.update(item.get(\"actions\", []))\n",
    "        global_nouns.update(item.get(\"nouns\", []))\n",
    "\n",
    "    return {\n",
    "        \"characters\": list(global_chars),\n",
    "        \"locations\": list(global_locs),\n",
    "        \"actions\": list(global_actions),\n",
    "        \"nouns\": list(global_nouns)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3200a02",
   "metadata": {},
   "source": [
    "‚úÖ STEP 5: Enhanced Suggestion ‚Äî Combine Context + Similarity\n",
    "This function now uses:\n",
    "\n",
    "Semantic similarity (like before)\n",
    "PLUS global context from the whole script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02af085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_missing_with_context(input_sentence, global_context, top_k=2):\n",
    "    # Step 1: Get suggestions from similar sentences (as before)\n",
    "    input_embedding = model.encode([input_sentence])\n",
    "    similarities = cosine_similarity(input_embedding, ref_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "\n",
    "    suggestions = {\n",
    "        \"characters\": set(),\n",
    "        \"locations\": set(),\n",
    "        \"actions\": set(),\n",
    "        \"nouns\": set()\n",
    "    }\n",
    "\n",
    "    for idx in top_indices:\n",
    "        match = reference_data[idx]\n",
    "        for key in suggestions:\n",
    "            suggestions[key].update(match[key])\n",
    "\n",
    "    # Step 2: Inject global context ‚Äî if something is known in script, suggest it!\n",
    "    for key in suggestions:\n",
    "        suggestions[key].update(global_context[key])\n",
    "\n",
    "    # Convert to lists\n",
    "    for key in suggestions:\n",
    "        suggestions[key] = list(suggestions[key])\n",
    "\n",
    "    return suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52feed24",
   "metadata": {},
   "source": [
    "‚úÖ STEP 6: Enrich with Context-Aware Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9bf0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_annotation_with_context(annotation, global_context):\n",
    "    sentence = annotation[\"sentence\"]\n",
    "    suggestions = suggest_missing_with_context(sentence, global_context)\n",
    "\n",
    "    for key in [\"characters\", \"locations\", \"actions\", \"nouns\"]:\n",
    "        existing = set(annotation[key])\n",
    "        new_items = [item for item in suggestions[key] if item not in existing]\n",
    "        annotation[key].extend(new_items)\n",
    "\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb455a04",
   "metadata": {},
   "source": [
    "‚úÖ STEP 7: Build Better Pixabay Query (Context-Aware)\n",
    "Now we can prioritize context ‚Äî e.g., if ‚ÄúAlex‚Äù and ‚Äúmountain‚Äù are global, include them even if not in sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c6642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pixabay_query_contextual(annotation, global_context):\n",
    "    parts = []\n",
    "\n",
    "    # Always include global characters if none locally\n",
    "    chars = annotation[\"characters\"] or global_context[\"characters\"]\n",
    "    if chars:\n",
    "        parts.append(\" \".join(chars))\n",
    "\n",
    "    # Include actions from sentence\n",
    "    if annotation[\"actions\"]:\n",
    "        parts.append(\" \".join(annotation[\"actions\"]))\n",
    "\n",
    "    # Include global locations + nouns if local ones are weak\n",
    "    loc_nouns = annotation[\"locations\"] + annotation[\"nouns\"]\n",
    "    if not loc_nouns:\n",
    "        loc_nouns = global_context[\"locations\"] + global_context[\"nouns\"]\n",
    "\n",
    "    if loc_nouns:\n",
    "        parts.append(\"in \" + \" \".join(loc_nouns))\n",
    "\n",
    "    return \" \".join(parts).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c895e8c",
   "metadata": {},
   "source": [
    "‚úÖ STEP 8: Run It on Your Full Script\n",
    "Paste your full script data (from your first message) into the file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b29914c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Global Context Built:\n",
      "Characters: ['Alex']\n",
      "Locations:  []\n",
      "Actions:    ['howl', 'dream', 'reach', 'block', 'say', 'grow', 'climb', 'creep']\n",
      "Nouns:      ['trail', 'way', 'training', 'hope', 'dream', 'year', 'expert', 'rock', 'wind', 'person', 'top', 'backpack', 'mountain', 'step', 'path']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üìù Sentence: Alex had always dreamed of reaching the top of Eagle's Peak, a mountain so tall many said it can't be climbed without years of training.\n",
      "‚Üí Enriched Characters: ['Alex']\n",
      "‚Üí Enriched Locations:  []\n",
      "‚Üí Enriched Actions:    ['dream', 'reach', 'say', 'climb', 'block', 'grow', 'howl', 'creep']\n",
      "‚Üí Enriched Nouns:      ['top', 'mountain', 'year', 'training', 'trail', 'way', 'hope', 'dream', 'expert', 'rock', 'wind', 'person', 'backpack', 'step', 'path']\n",
      "‚Üí Pixabay Query:       \"Alex dream reach say climb block grow howl creep in top mountain year training trail way hope dream expert rock wind person backpack step path\"\n",
      "------------------------------------------------------------\n",
      "üìù Sentence: But Alex wasn't an expert.\n",
      "‚Üí Enriched Characters: ['Alex']\n",
      "‚Üí Enriched Locations:  []\n",
      "‚Üí Enriched Actions:    ['dream', 'reach', 'block', 'say', 'grow', 'howl', 'creep', 'climb']\n",
      "‚Üí Enriched Nouns:      ['expert', 'trail', 'way', 'training', 'hope', 'dream', 'year', 'rock', 'wind', 'person', 'top', 'backpack', 'mountain', 'step', 'path']\n",
      "‚Üí Pixabay Query:       \"Alex dream reach block say grow howl creep climb in expert trail way training hope dream year rock wind person top backpack mountain step path\"\n",
      "------------------------------------------------------------\n",
      "üìù Sentence: Just a person with a dream and a backpack full of hope.\n",
      "‚Üí Enriched Characters: ['Alex']\n",
      "‚Üí Enriched Locations:  []\n",
      "‚Üí Enriched Actions:    ['dream', 'reach', 'block', 'say', 'grow', 'howl', 'creep', 'climb']\n",
      "‚Üí Enriched Nouns:      ['person', 'dream', 'backpack', 'hope', 'trail', 'way', 'training', 'year', 'expert', 'rock', 'wind', 'top', 'mountain', 'step', 'path']\n",
      "‚Üí Pixabay Query:       \"Alex dream reach block say grow howl creep climb in person dream backpack hope trail way training year expert rock wind top mountain step path\"\n",
      "------------------------------------------------------------\n",
      "üìù Sentence: The first steps were easy.\n",
      "‚Üí Enriched Characters: ['Alex']\n",
      "‚Üí Enriched Locations:  []\n",
      "‚Üí Enriched Actions:    ['block', 'reach', 'dream', 'say', 'grow', 'howl', 'creep', 'climb']\n",
      "‚Üí Enriched Nouns:      ['step', 'trail', 'way', 'training', 'hope', 'dream', 'year', 'expert', 'rock', 'top', 'person', 'wind', 'backpack', 'mountain', 'path']\n",
      "‚Üí Pixabay Query:       \"Alex block reach dream say grow howl creep climb in step trail way training hope dream year expert rock top person wind backpack mountain path\"\n",
      "------------------------------------------------------------\n",
      "üìù Sentence: The path was clear.\n",
      "‚Üí Enriched Characters: ['Alex']\n",
      "‚Üí Enriched Locations:  []\n",
      "‚Üí Enriched Actions:    ['block', 'reach', 'dream', 'say', 'grow', 'howl', 'creep', 'climb']\n",
      "‚Üí Enriched Nouns:      ['path', 'trail', 'way', 'training', 'hope', 'dream', 'year', 'expert', 'rock', 'top', 'person', 'wind', 'backpack', 'mountain', 'step']\n",
      "‚Üí Pixabay Query:       \"Alex block reach dream say grow howl creep climb in path trail way training hope dream year expert rock top person wind backpack mountain step\"\n",
      "------------------------------------------------------------\n",
      "üìù Sentence: But soon the trail grew steeper.\n",
      "‚Üí Enriched Characters: ['Alex']\n",
      "‚Üí Enriched Locations:  []\n",
      "‚Üí Enriched Actions:    ['grow', 'howl', 'dream', 'reach', 'block', 'say', 'climb', 'creep']\n",
      "‚Üí Enriched Nouns:      ['trail', 'way', 'training', 'hope', 'dream', 'year', 'expert', 'rock', 'wind', 'person', 'top', 'backpack', 'mountain', 'step', 'path']\n",
      "‚Üí Pixabay Query:       \"Alex grow howl dream reach block say climb creep in trail way training hope dream year expert rock wind person top backpack mountain step path\"\n",
      "------------------------------------------------------------\n",
      "üìù Sentence: Rocks blocked the way.\n",
      "‚Üí Enriched Characters: ['Alex']\n",
      "‚Üí Enriched Locations:  []\n",
      "‚Üí Enriched Actions:    ['block', 'dream', 'reach', 'say', 'grow', 'howl', 'creep', 'climb']\n",
      "‚Üí Enriched Nouns:      ['rock', 'way', 'trail', 'training', 'hope', 'dream', 'year', 'expert', 'top', 'person', 'wind', 'backpack', 'mountain', 'step', 'path']\n",
      "‚Üí Pixabay Query:       \"Alex block dream reach say grow howl creep climb in rock way trail training hope dream year expert top person wind backpack mountain step path\"\n",
      "------------------------------------------------------------\n",
      "üìù Sentence: The wind howled.\n",
      "‚Üí Enriched Characters: ['Alex']\n",
      "‚Üí Enriched Locations:  []\n",
      "‚Üí Enriched Actions:    ['howl', 'block', 'reach', 'dream', 'say', 'grow', 'creep', 'climb']\n",
      "‚Üí Enriched Nouns:      ['wind', 'trail', 'way', 'hope', 'training', 'dream', 'year', 'expert', 'rock', 'top', 'person', 'backpack', 'mountain', 'step', 'path']\n",
      "‚Üí Pixabay Query:       \"Alex howl block reach dream say grow creep climb in wind trail way hope training dream year expert rock top person backpack mountain step path\"\n",
      "------------------------------------------------------------\n",
      "üìù Sentence: Doubt crept in.\n",
      "‚Üí Enriched Characters: ['Alex']\n",
      "‚Üí Enriched Locations:  []\n",
      "‚Üí Enriched Actions:    ['creep', 'block', 'reach', 'dream', 'say', 'grow', 'howl', 'climb']\n",
      "‚Üí Enriched Nouns:      ['trail', 'way', 'training', 'hope', 'dream', 'year', 'expert', 'rock', 'top', 'person', 'wind', 'backpack', 'mountain', 'step', 'path']\n",
      "‚Üí Pixabay Query:       \"Alex creep block reach dream say grow howl climb in trail way training hope dream year expert rock top person wind backpack mountain step path\"\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Your full script (from your original input)\n",
    "    script_data = [\n",
    "        {\n",
    "            \"sentence\": \"Alex had always dreamed of reaching the top of Eagle's Peak, a mountain so tall many said it can't be climbed without years of training.\",\n",
    "            \"characters\": [\"Alex\"],\n",
    "            \"locations\": [],\n",
    "            \"actions\": [\"dream\", \"reach\", \"say\", \"climb\"],\n",
    "            \"nouns\": [\"top\", \"mountain\", \"year\", \"training\"]\n",
    "        },\n",
    "        {\n",
    "            \"sentence\": \"But Alex wasn't an expert.\",\n",
    "            \"characters\": [\"Alex\"],\n",
    "            \"locations\": [],\n",
    "            \"actions\": [],\n",
    "            \"nouns\": [\"expert\"]\n",
    "        },\n",
    "        {\n",
    "            \"sentence\": \"Just a person with a dream and a backpack full of hope.\",\n",
    "            \"characters\": [],\n",
    "            \"locations\": [],\n",
    "            \"actions\": [],\n",
    "            \"nouns\": [\"person\", \"dream\", \"backpack\", \"hope\"]\n",
    "        },\n",
    "        {\n",
    "            \"sentence\": \"The first steps were easy.\",\n",
    "            \"characters\": [],\n",
    "            \"locations\": [],\n",
    "            \"actions\": [],\n",
    "            \"nouns\": [\"step\"]\n",
    "        },\n",
    "        {\n",
    "            \"sentence\": \"The path was clear.\",\n",
    "            \"characters\": [],\n",
    "            \"locations\": [],\n",
    "            \"actions\": [],\n",
    "            \"nouns\": [\"path\"]\n",
    "        },\n",
    "        {\n",
    "            \"sentence\": \"But soon the trail grew steeper.\",\n",
    "            \"characters\": [],\n",
    "            \"locations\": [],\n",
    "            \"actions\": [\"grow\"],\n",
    "            \"nouns\": [\"trail\"]\n",
    "        },\n",
    "        {\n",
    "            \"sentence\": \"Rocks blocked the way.\",\n",
    "            \"characters\": [],\n",
    "            \"locations\": [],\n",
    "            \"actions\": [\"block\"],\n",
    "            \"nouns\": [\"rock\", \"way\"]\n",
    "        },\n",
    "        {\n",
    "            \"sentence\": \"The wind howled.\",\n",
    "            \"characters\": [],\n",
    "            \"locations\": [],\n",
    "            \"actions\": [\"howl\"],\n",
    "            \"nouns\": [\"wind\"]\n",
    "        },\n",
    "        {\n",
    "            \"sentence\": \"Doubt crept in.\",\n",
    "            \"characters\": [],\n",
    "            \"locations\": [],\n",
    "            \"actions\": [\"creep\"],\n",
    "            \"nouns\": []\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Step 1: Build global context from entire script\n",
    "    global_context = build_global_context(script_data)\n",
    "    print(\"üåç Global Context Built:\")\n",
    "    print(f\"Characters: {global_context['characters']}\")\n",
    "    print(f\"Locations:  {global_context['locations']}\")\n",
    "    print(f\"Actions:    {global_context['actions']}\")\n",
    "    print(f\"Nouns:      {global_context['nouns']}\\n\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    # Step 2: Enrich each sentence using global context\n",
    "    enriched_script = []\n",
    "    for item in script_data:\n",
    "        enriched = enrich_annotation_with_context(item.copy(), global_context)  # copy to avoid mutating original\n",
    "        query = build_pixabay_query_contextual(enriched, global_context)\n",
    "        enriched[\"pixabay_query\"] = query\n",
    "        enriched_script.append(enriched)\n",
    "\n",
    "        print(f\"üìù Sentence: {item['sentence']}\")\n",
    "        print(f\"‚Üí Enriched Characters: {enriched['characters']}\")\n",
    "        print(f\"‚Üí Enriched Locations:  {enriched['locations']}\")\n",
    "        print(f\"‚Üí Enriched Actions:    {enriched['actions']}\")\n",
    "        print(f\"‚Üí Enriched Nouns:      {enriched['nouns']}\")\n",
    "        print(f\"‚Üí Pixabay Query:       \\\"{query}\\\"\")\n",
    "        print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84625c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Enriched script saved to 'enriched_script.json'\n"
     ]
    }
   ],
   "source": [
    "    # Save enriched script\n",
    "with open(\"enriched_script.json\", \"w\") as f:\n",
    "    json.dump(enriched_script, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Enriched script saved to 'enriched_script.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6eb68c",
   "metadata": {},
   "source": [
    "‚úÖ GOAL: Make SMART, RELEVANT Suggestions ‚Äî Not DUMP EVERYTHING\n",
    "üõ†Ô∏è STEP-BY-STEP FIX ‚Äî Let‚Äôs Refine the System\n",
    "‚úÖ STEP 1: Don‚Äôt Inject ALL Global Context ‚Äî Only What‚Äôs Missing & Plausible\n",
    "Update your suggestion function to be selective.\n",
    "\n",
    "Replace your current suggest_missing_with_context() with this smarter version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74a08d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_missing_with_context(input_sentence, global_context, top_k=2):\n",
    "    # Step 1: Get suggestions from similar sentences (semantic match)\n",
    "    input_embedding = model.encode([input_sentence])\n",
    "    similarities = cosine_similarity(input_embedding, ref_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "\n",
    "    semantic_suggestions = {\n",
    "        \"characters\": set(),\n",
    "        \"locations\": set(),\n",
    "        \"actions\": set(),\n",
    "        \"nouns\": set()\n",
    "    }\n",
    "\n",
    "    for idx in top_indices:\n",
    "        match = reference_data[idx]\n",
    "        for key in semantic_suggestions:\n",
    "            semantic_suggestions[key].update(match[key])\n",
    "\n",
    "    # Step 2: Fill only MISSING slots with global context ‚Äî don't override!\n",
    "    final_suggestions = {}\n",
    "    for key in [\"characters\", \"locations\", \"actions\", \"nouns\"]:\n",
    "        # Start with semantic suggestions\n",
    "        suggested = set(semantic_suggestions[key])\n",
    "        # Add from global ONLY if nothing was suggested AND field is empty in original\n",
    "        if len(suggested) == 0:\n",
    "            suggested.update(global_context[key])\n",
    "        final_suggestions[key] = list(suggested)\n",
    "\n",
    "    return final_suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f9469b",
   "metadata": {},
   "source": [
    "‚úÖ STEP 2: Improve Query Builder ‚Äî Keep It Short & Relevant\n",
    "Replace your build_pixabay_query_contextual() with this cleaner version:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f3b19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pixabay_query_contextual(annotation, global_context):\n",
    "    parts = []\n",
    "\n",
    "    # Characters: use local, or global if local empty\n",
    "    chars = annotation[\"characters\"][:2]  # max 2 characters\n",
    "    if not chars and global_context[\"characters\"]:\n",
    "        chars = global_context[\"characters\"][:1]  # just main character\n",
    "    if chars:\n",
    "        parts.append(\" \".join(chars))\n",
    "\n",
    "    # Actions: use only LOCAL ones (max 2)\n",
    "    actions = annotation[\"actions\"][:2]\n",
    "    if actions:\n",
    "        parts.append(\" \".join(actions))\n",
    "\n",
    "    # Nouns + Locations: combine, dedupe, limit to 4 total\n",
    "    loc_nouns = list(set(annotation[\"locations\"] + annotation[\"nouns\"]))[:4]\n",
    "    if not loc_nouns:\n",
    "        # Fallback: take up to 3 from global\n",
    "        fallback = list(set(global_context[\"locations\"] + global_context[\"nouns\"]))[:3]\n",
    "        loc_nouns = fallback\n",
    "\n",
    "    if loc_nouns:\n",
    "        parts.append(\"in \" + \" \".join(loc_nouns))\n",
    "\n",
    "    return \" \".join(parts).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ccd23",
   "metadata": {},
   "source": [
    "‚úÖ STEP 3: Optional ‚Äî Filter Irrelevant Global Nouns\n",
    "Some global nouns like \"expert\", \"person\", \"year\" are too abstract for image search.\n",
    "\n",
    "Add a small filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a9146ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "IRRELEVANT_NOUNS = {\"person\", \"expert\", \"year\", \"training\", \"hope\", \"dream\"}  # too abstract\n",
    "\n",
    "def filter_irrelevant(items):\n",
    "    return [item for item in items if item not in IRRELEVANT_NOUNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d346fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_annotation_with_context(annotation, global_context):\n",
    "    # Copy structure safely\n",
    "    enriched = {\n",
    "        \"sentence\": annotation[\"sentence\"],\n",
    "        \"characters\": annotation[\"characters\"].copy(),\n",
    "        \"locations\": annotation[\"locations\"].copy(),\n",
    "        \"actions\": annotation[\"actions\"].copy(),\n",
    "        \"nouns\": annotation[\"nouns\"].copy()\n",
    "    }\n",
    "\n",
    "    suggestions = suggest_missing_with_context(enriched[\"sentence\"], global_context)\n",
    "\n",
    "    for key in [\"characters\", \"locations\", \"actions\", \"nouns\"]:\n",
    "        existing = set(enriched[key])\n",
    "        new_items = [item for item in suggestions[key] if item not in existing]\n",
    "        enriched[key].extend(new_items)\n",
    "\n",
    "    return enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb13549f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
