{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ccace6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 Building global context from script...\n",
      "Characters: ['Alex']\n",
      "Locations:  []\n",
      "Actions:    ['block', 'climb', 'reach', 'creep', 'dream', 'grow', 'say', 'howl']\n",
      "Nouns:      ['path', 'expert', 'wind', 'trail', 'hope', 'top', 'dream', 'rock', 'way', 'mountain', 'training', 'backpack', 'step', 'year', 'person']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "📝 Sentence: Alex had always dreamed of reaching the top of Eagle's Peak, a mountain so tall many said it can't be climbed without years of training.\n",
      "→ Characters: ['Alex']\n",
      "→ Locations:  []\n",
      "→ Actions:    ['dream', 'reach', 'say', 'climb']\n",
      "→ Nouns:      ['top', 'mountain', 'year', 'training', 'expert']\n",
      "→ ✅ Pixabay Query: \"Alex dream reach in mountain\"\n",
      "------------------------------------------------------------\n",
      "📝 Sentence: But Alex wasn't an expert.\n",
      "→ Characters: ['Alex']\n",
      "→ Locations:  []\n",
      "→ Actions:    ['climb', 'dream', 'reach', 'say']\n",
      "→ Nouns:      ['expert', 'top', 'mountain', 'training', 'year']\n",
      "→ ✅ Pixabay Query: \"Alex climb dream in mountain\"\n",
      "------------------------------------------------------------\n",
      "📝 Sentence: Just a person with a dream and a backpack full of hope.\n",
      "→ Characters: ['Alex']\n",
      "→ Locations:  []\n",
      "→ Actions:    ['climb', 'dream', 'reach', 'say']\n",
      "→ Nouns:      ['person', 'dream', 'backpack', 'hope', 'top', 'mountain', 'training', 'year']\n",
      "→ ✅ Pixabay Query: \"Alex climb dream in mountain backpack\"\n",
      "------------------------------------------------------------\n",
      "📝 Sentence: The first steps were easy.\n",
      "→ Characters: ['Alex']\n",
      "→ Locations:  []\n",
      "→ Actions:    ['block', 'climb', 'reach', 'creep', 'dream', 'grow', 'say', 'howl']\n",
      "→ Nouns:      ['step', 'path']\n",
      "→ ✅ Pixabay Query: \"Alex block climb in path\"\n",
      "------------------------------------------------------------\n",
      "📝 Sentence: The path was clear.\n",
      "→ Characters: ['Alex']\n",
      "→ Locations:  []\n",
      "→ Actions:    ['block', 'climb', 'reach', 'creep', 'dream', 'grow', 'say', 'howl']\n",
      "→ Nouns:      ['path', 'step']\n",
      "→ ✅ Pixabay Query: \"Alex block climb in path\"\n",
      "------------------------------------------------------------\n",
      "📝 Sentence: But soon the trail grew steeper.\n",
      "→ Characters: ['Alex']\n",
      "→ Locations:  []\n",
      "→ Actions:    ['grow', 'dream', 'climb', 'reach', 'say']\n",
      "→ Nouns:      ['trail', 'top', 'mountain', 'training', 'year']\n",
      "→ ✅ Pixabay Query: \"Alex grow dream in mountain trail\"\n",
      "------------------------------------------------------------\n",
      "📝 Sentence: Rocks blocked the way.\n",
      "→ Characters: ['Alex']\n",
      "→ Locations:  []\n",
      "→ Actions:    ['block']\n",
      "→ Nouns:      ['rock', 'way', 'path']\n",
      "→ ✅ Pixabay Query: \"Alex block in path rock\"\n",
      "------------------------------------------------------------\n",
      "📝 Sentence: The wind howled.\n",
      "→ Characters: ['Alex']\n",
      "→ Locations:  []\n",
      "→ Actions:    ['howl', 'grow']\n",
      "→ Nouns:      ['wind', 'trail']\n",
      "→ ✅ Pixabay Query: \"Alex howl grow in wind trail\"\n",
      "------------------------------------------------------------\n",
      "📝 Sentence: Doubt crept in.\n",
      "→ Characters: ['Alex']\n",
      "→ Locations:  []\n",
      "→ Actions:    ['creep']\n",
      "→ Nouns:      ['path']\n",
      "→ ✅ Pixabay Query: \"Alex creep in path\"\n",
      "------------------------------------------------------------\n",
      "\n",
      "✅ Saved clean enriched script to 'enriched_script_clean.json'\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# =============================\n",
    "# STEP 1: Load Model & Reference Data\n",
    "# =============================\n",
    "\n",
    "# Load reference knowledge base\n",
    "with open(\"reference_data.json\", \"r\") as f:\n",
    "    reference_data = json.load(f)\n",
    "\n",
    "# Load sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode reference sentences\n",
    "ref_sentences = [item[\"sentence\"] for item in reference_data]\n",
    "ref_embeddings = model.encode(ref_sentences)\n",
    "\n",
    "# =============================\n",
    "# STEP 2: Define Helper Functions\n",
    "# =============================\n",
    "\n",
    "# Filter out abstract or non-visual nouns\n",
    "IRRELEVANT_NOUNS = {\"person\", \"expert\", \"year\", \"training\", \"hope\", \"dream\", \"mind\", \"way\", \"step\", \"top\"}\n",
    "\n",
    "def filter_irrelevant(items):\n",
    "    return [item for item in items if item not in IRRELEVANT_NOUNS]\n",
    "\n",
    "# Build global context from entire script\n",
    "def build_global_context(script_data):\n",
    "    global_chars = set()\n",
    "    global_locs = set()\n",
    "    global_actions = set()\n",
    "    global_nouns = set()\n",
    "\n",
    "    for item in script_data:\n",
    "        global_chars.update(item.get(\"characters\", []))\n",
    "        global_locs.update(item.get(\"locations\", []))\n",
    "        global_actions.update(item.get(\"actions\", []))\n",
    "        global_nouns.update(item.get(\"nouns\", []))\n",
    "\n",
    "    return {\n",
    "        \"characters\": list(global_chars),\n",
    "        \"locations\": list(global_locs),\n",
    "        \"actions\": list(global_actions),\n",
    "        \"nouns\": list(global_nouns)\n",
    "    }\n",
    "\n",
    "# Suggest missing entities — semantic first, global context as fallback\n",
    "def suggest_missing_with_context(input_sentence, global_context, top_k=2):\n",
    "    # Step 1: Semantic suggestions from similar reference sentences\n",
    "    input_embedding = model.encode([input_sentence])\n",
    "    similarities = cosine_similarity(input_embedding, ref_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "\n",
    "    semantic_suggestions = {\n",
    "        \"characters\": set(),\n",
    "        \"locations\": set(),\n",
    "        \"actions\": set(),\n",
    "        \"nouns\": set()\n",
    "    }\n",
    "\n",
    "    for idx in top_indices:\n",
    "        match = reference_data[idx]\n",
    "        for key in semantic_suggestions:\n",
    "            semantic_suggestions[key].update(match[key])\n",
    "\n",
    "    # Step 2: Only use global context if semantic gave nothing AND field is empty\n",
    "    final_suggestions = {}\n",
    "    for key in [\"characters\", \"locations\", \"actions\", \"nouns\"]:\n",
    "        suggested = set(semantic_suggestions[key])\n",
    "        if len(suggested) == 0:\n",
    "            # Fallback to global context only if original was empty\n",
    "            suggested.update(global_context[key])\n",
    "        final_suggestions[key] = list(suggested)\n",
    "\n",
    "    return final_suggestions\n",
    "\n",
    "# Enrich annotation without mutating original\n",
    "def enrich_annotation_with_context(annotation, global_context):\n",
    "    # Safe copy\n",
    "    enriched = {\n",
    "        \"sentence\": annotation[\"sentence\"],\n",
    "        \"characters\": annotation[\"characters\"].copy(),\n",
    "        \"locations\": annotation[\"locations\"].copy(),\n",
    "        \"actions\": annotation[\"actions\"].copy(),\n",
    "        \"nouns\": annotation[\"nouns\"].copy()\n",
    "    }\n",
    "\n",
    "    suggestions = suggest_missing_with_context(enriched[\"sentence\"], global_context)\n",
    "\n",
    "    for key in [\"characters\", \"locations\", \"actions\", \"nouns\"]:\n",
    "        existing = set(enriched[key])\n",
    "        new_items = [item for item in suggestions[key] if item not in existing]\n",
    "        enriched[key].extend(new_items)\n",
    "\n",
    "    return enriched\n",
    "\n",
    "# Build clean, short, image-friendly Pixabay query\n",
    "def build_pixabay_query_contextual(annotation, global_context):\n",
    "    parts = []\n",
    "\n",
    "    # Characters: max 2 (prefer local, fallback to global)\n",
    "    chars = annotation[\"characters\"][:2]\n",
    "    if not chars and global_context[\"characters\"]:\n",
    "        chars = global_context[\"characters\"][:1]\n",
    "    if chars:\n",
    "        parts.append(\" \".join(chars))\n",
    "\n",
    "    # Actions: max 2 from local\n",
    "    actions = annotation[\"actions\"][:2]\n",
    "    if actions:\n",
    "        parts.append(\" \".join(actions))\n",
    "\n",
    "    # Locations + Nouns: combine, filter, dedupe, max 4\n",
    "    loc_nouns = filter_irrelevant(list(set(annotation[\"locations\"] + annotation[\"nouns\"])))[:4]\n",
    "    if not loc_nouns:\n",
    "        fallback = filter_irrelevant(list(set(global_context[\"locations\"] + global_context[\"nouns\"])))[:3]\n",
    "        loc_nouns = fallback\n",
    "\n",
    "    if loc_nouns:\n",
    "        parts.append(\"in \" + \" \".join(loc_nouns))\n",
    "\n",
    "    return \" \".join(parts).strip()\n",
    "\n",
    "# =============================\n",
    "# STEP 3: Your Script Data (Input)\n",
    "# =============================\n",
    "\n",
    "script_data = [\n",
    "    {\n",
    "        \"sentence\": \"Alex had always dreamed of reaching the top of Eagle's Peak, a mountain so tall many said it can't be climbed without years of training.\",\n",
    "        \"characters\": [\"Alex\"],\n",
    "        \"locations\": [],\n",
    "        \"actions\": [\"dream\", \"reach\", \"say\", \"climb\"],\n",
    "        \"nouns\": [\"top\", \"mountain\", \"year\", \"training\"]\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"But Alex wasn't an expert.\",\n",
    "        \"characters\": [\"Alex\"],\n",
    "        \"locations\": [],\n",
    "        \"actions\": [],\n",
    "        \"nouns\": [\"expert\"]\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Just a person with a dream and a backpack full of hope.\",\n",
    "        \"characters\": [],\n",
    "        \"locations\": [],\n",
    "        \"actions\": [],\n",
    "        \"nouns\": [\"person\", \"dream\", \"backpack\", \"hope\"]\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"The first steps were easy.\",\n",
    "        \"characters\": [],\n",
    "        \"locations\": [],\n",
    "        \"actions\": [],\n",
    "        \"nouns\": [\"step\"]\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"The path was clear.\",\n",
    "        \"characters\": [],\n",
    "        \"locations\": [],\n",
    "        \"actions\": [],\n",
    "        \"nouns\": [\"path\"]\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"But soon the trail grew steeper.\",\n",
    "        \"characters\": [],\n",
    "        \"locations\": [],\n",
    "        \"actions\": [\"grow\"],\n",
    "        \"nouns\": [\"trail\"]\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Rocks blocked the way.\",\n",
    "        \"characters\": [],\n",
    "        \"locations\": [],\n",
    "        \"actions\": [\"block\"],\n",
    "        \"nouns\": [\"rock\", \"way\"]\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"The wind howled.\",\n",
    "        \"characters\": [],\n",
    "        \"locations\": [],\n",
    "        \"actions\": [\"howl\"],\n",
    "        \"nouns\": [\"wind\"]\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Doubt crept in.\",\n",
    "        \"characters\": [],\n",
    "        \"locations\": [],\n",
    "        \"actions\": [\"creep\"],\n",
    "        \"nouns\": []\n",
    "    }\n",
    "]\n",
    "\n",
    "# =============================\n",
    "# STEP 4: Run Enrichment\n",
    "# =============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🌍 Building global context from script...\")\n",
    "    global_context = build_global_context(script_data)\n",
    "    print(f\"Characters: {global_context['characters']}\")\n",
    "    print(f\"Locations:  {global_context['locations']}\")\n",
    "    print(f\"Actions:    {global_context['actions']}\")\n",
    "    print(f\"Nouns:      {global_context['nouns']}\\n\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    enriched_script = []\n",
    "\n",
    "    for item in script_data:\n",
    "        enriched = enrich_annotation_with_context(item, global_context)\n",
    "        query = build_pixabay_query_contextual(enriched, global_context)\n",
    "        enriched[\"pixabay_query\"] = query\n",
    "        enriched_script.append(enriched)\n",
    "\n",
    "        print(f\"📝 Sentence: {item['sentence']}\")\n",
    "        print(f\"→ Characters: {enriched['characters']}\")\n",
    "        print(f\"→ Locations:  {enriched['locations']}\")\n",
    "        print(f\"→ Actions:    {enriched['actions']}\")\n",
    "        print(f\"→ Nouns:      {enriched['nouns']}\")\n",
    "        print(f\"→ ✅ Pixabay Query: \\\"{query}\\\"\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    # Optional: Save output\n",
    "    with open(\"enriched_script_clean.json\", \"w\") as f:\n",
    "        json.dump(enriched_script, f, indent=2)\n",
    "\n",
    "    print(\"\\n✅ Saved clean enriched script to 'enriched_script_clean.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e52feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
